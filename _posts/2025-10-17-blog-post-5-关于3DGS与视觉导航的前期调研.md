---
title: '关于3DGS与3D视觉导航的前期调研'
date: 2025-10-17
permalink: /posts/2025/10/blog-post-5/
tags:
  - 3DGS
  - SLAM
  - CV
---

对于3DGS与视觉导航，SLAM领域结合的两篇论文的简要个人理解与调研。[GaussNav](https://arxiv.org/abs/2403.11625) [SplaTAM](https://github.com/spla-tam/SplaTAM)


# 关于3DGS与3D视觉导航的前期调研

目前，我个人查到了两篇顶会论文是融合了3DGS和视觉导航的。而这个领域的相关综述非常少，所以我将就这两篇论文进行一些探究和总结。
<br>

## 一、 到底在关注什么问题，解决了什么

这两篇论文均聚焦于利用3DGS技术解决视觉导航与SLAM领域中地图表示精度低，渲染慢，相机跟踪不准等核心问题。
<br>

### 1. 视觉导航是什么
视觉导航是具身智能的核心任务之一，指智能体（无论是机器人还是虚拟智能体），他们仅通过视觉传感器，例如RGB相机，RGB-D相机获取环境观测信息，自助规划路径并移动到目标位置。这是一个端到端的能力，从视觉感知到动作决策。
<br>

**核心定义**：
根据任务目标的描述形式（如语言指令、目标图像、类别标签），智能体利用视觉观测构建环境认知，避开障碍物并高效抵达目标，**无需依赖预设地图或 GPS**。

**关键目标**：
- 精准定位目标：区分目标与干扰物。
- 高效路径规划：平衡探索效率与导航捷径。
- 鲁棒性：应对视角变换（目标物的不同视角）、环境噪声、动态障碍物（临时出现的物体）。

这其中，有一个关键技术叫做SLAM（Simultaneous Localization and Mapping），同步定位与地图构建。
<br>

### 2. SLAM需要完成的任务
这是机器人感知与导航的基础技术，指智能体在未知环境中，通过传感器（例如RGB-D相机、激光雷达）同时完成两个工作：
- 估计自身环境中的位置（Localization）。
- 构建环境的空间表示（Mapping）。
<br>

**核心定义**：
在没有预设地图的情况下，智能体通过连续帧的传感器数据，实时计算自身运动轨迹和姿态，并增量式的构建环境的稠密或者稀疏地图。

**定位和地图相互以来**：地图为定位提供参考，定位结果又为地图更新提供坐标基准。

**关键目标**：
- 精确定位：估计自身位置，避免漂移。
- 地图质量：保留环境细节（墙角、家具纹理），支持下有任务（例如导航，场景重建）。
- 高效地图构建：实时更新地图，减少冗余信息。
- 鲁棒性：应对环境变化（动态障碍物、视角变化）、传感器噪声（如 RGB-D 相机的深度缺失像素）、动态环境（如人走过场景）。
<br>

### 3. 这两篇论文分别关注什么地方
这两篇论文在之前所提的关注点基础上，分别在实例图像目标导航和稠密RGB-D SLAM任务中实现了性能突破。
<br>

#### 3.1 核心问题与解决方案
**GaussNav：实例图像目标导航的精准定位问题**
- 核心问题：传统基于2D BEV地图的导航方法，无法保留场景3D几何结构和物体纹理细节，导致在IIN任务中难以区分目标实例与相似干扰物，跨楼层导航能力弱。
- 解决方案：引入3DGS，提出语义高斯地图（Semantic Gaussian），融合3D几何，语义标签和纹理特征，让智能体直接通过目标图像匹配渲染结果，精准定位目标实例，无需额外验证

**SplaTAM：稠密RGB-D SLAM的实时性与精度平衡问题**
- 核心问题：现有SLAM方法存在缺陷——显示表示渲染质量低，如点云、体素；隐式表示如NeRF计算效率差，容易遗忘
- 解决方案：首次将3DGS作为SLAM的地图表示，通过实时跟踪-致密化-地图更新流程，实现亚厘米级相机定位和高保真场景重建。
<br>

#### 3.2 二者的关联
两篇论文分别聚焦视觉导航和SLAM，但是在智能体环境认知上有强关联，也有明确分工：
| 维度 | 视觉导航（GaussNav） | SLAM（SplaTAM） |
|-------|-------|-------|
| **核心目标** | 从 “起点” 到 “目标” 的路径规划与执行，核心是 “决策” | 从 “无地图” 到 “有地图 + 自身位姿”，核心是 “感知建模” |
| **环境认知依赖** | 依赖 SLAM 输出的地图与位姿（GaussNav 的探索阶段本质是轻量 SLAM） | 不依赖外部地图，自主构建地图与位姿 |
| **任务输出** | 动作序列（如 “前进 25cm→左转 25°→停止” | 相机轨迹（位姿序列）+ 稠密地图（语义高斯 / 点云） |
| **论文中的协作** | GaussNav 的 “语义高斯地图” 需 SLAM 提供的相机位姿来初始化高斯 | SplaTAM 的 “稠密地图” 可直接作为视觉导航的环境认知载体 |

两者共同构成智能体自主移动的基础：SLAM提供环境认知原料（地图+位姿），视觉导航是在SLAM提供的原料基础上进行的决策。
<br>

## 二、 如何解决的，流程是什么
SLAM属于3D视觉导航的上游任务，主要解决的是环境认知问题，而视觉导航则是在SLAM的基础上进行的决策，属于下游任务。
<br>

### 1.SplaTAM：三阶段的SLAM流程
SplaTAM的三阶段流程是稠密RGB-D SLAM的经典落地范式，完整体现“定位-地图”的闭环依赖关系。

- 1. **相机跟踪（comera tracking）**：基于前一帧位姿进行匀速初始化，通过可微渲染生成当前帧的颜色、深度、轮廓图，仅对 “轮廓置信度> 0.99” 的像素（即地图已稳定区域）计算损失（RGB L1 + 深度 L1），迭代优化当前帧位姿；
- 2. **高斯致密化（gaussian densification）**：生成 “致密化掩码”—— 标记 “轮廓置信度 < 0.5”（地图稀疏区）或 “真实深度 < 预测深度且误差 > 50×MDE”（几何偏差区），在这些区域新增高斯，确保地图覆盖全场景；
- 3. **地图更新（map update）**：固定已优化的相机位姿，通过可微渲染优化所有高斯参数（最小化 RGB L1+SSIM + 深度 L1 损失），同时剔除透明度接近 0 或半径过大的无效高斯，保持地图精简高效。
<br>

### 2.GaussNav：三阶段的导航流程
GaussNav 将视觉导航拆解为三阶段，完整覆盖 “感知 - 建模 - 决策” 全链路，是视觉导航任务的典型落地范式：
- 1. 前沿探索：智能体通过 “探索地图”（标记已探索区域）和 “障碍地图”（标记障碍物），优先探索 “已探索 - 未探索” 边界（前沿点），收集 RGB-D 图像和相机位姿，为地图构建提供数据；
- 2. 语义高斯构建：将收集的观测转化为语义高斯地图 —— 通过 MaskRCNN 标注语义标签，用可微渲染优化高斯参数（颜色、位置、透明度），保留 3D 几何与纹理；
- 3. 目标匹配与导航：对目标图像分类（确定语义类别，利用ResNet-50），渲染同类实例的多视角图像，用 DISK 提取关键点、LightGlue 匹配，定位目标后将 3D 高斯投影为 2D BEV 网格，用 FMM（快速行进法）规划路径。

### 3. GsuaaianNav前沿探索阶段和SplaTAM的依赖关系
两者的底层交集在于为3D高斯地图的构建提供“带精准位姿的环境观测数据”，是后续语义建模、导航或者SLAM任务的基础。具体体现在两个方面：
 <br>

1. **数据需求的一致性**
    GaussianNav 的前沿探索阶段，核心目标是收集 “RGB-D 图像 + 相机位姿” 数据 —— 只有获取每个观测帧的精准位姿，才能将 2D 图像反投影为 3D 高斯的初始质心（μ）、半径（r）等参数，避免后续语义高斯地图出现几何失真。
    <br>

    SplaTAM 的核心能力正是 “实时输出精准相机位姿 + 稠密 3D 高斯地图”：其相机跟踪模块通过 3D 高斯的可微渲染（对比渲染 RGB / 深度与输入图像），能实现亚厘米级位姿估计（如在 Replica 数据集上 ATE RMSE 低至 0.36cm），可直接为 GaussianNav 的探索阶段提供无漂移的位姿数据，解决传统 “粗略视觉里程计” 导致的位姿累积误差问题。
<br>

2. **地图构建的依赖性**
    GaussianNav 的前沿探索需通过 “探索地图（标记已探索区域）+ 障碍地图（标记障碍物）” 检测 “已探索 - 未探索边界（前沿点）”，才能高效规划探索路径。但这两张地图的准确性依赖实时环境建模 —— 若某区域未被精准建模（如纹理缺失处），可能误判 “前沿点” 位置，导致探索冗余或遗漏。
<br>

### 4. GaussianNav前沿探索阶段和SplaTAM的不同点
尽管存在数据与地图层面的关联，但两者因聚焦任务不同（视觉导航 vs. 稠密 SLAM），在核心目标、执行逻辑上存在显著差异，具体如下表所示：
| 维度 | GaussianNav 的前沿探索阶段 | SplaTAM 的核心流程（跟踪 + 致密化 + 更新） |
|-------|-------|-------|
| **核心目标** | 高效遍历未知环境，收集 “覆盖全、无冗余” 的观测数据，为后续 “语义高斯构建” 打基础 | 同步实现 “精准相机定位” 与 “高保真 3D 高斯地图构建”，输出可用的地图与轨迹 |
| **位姿来源于精度** | 依赖探索过程中实时计算的基础位姿（如简化版视觉里程计），精度较低（未明确亚厘米级）| 通过可微渲染优化（最小化 RGB L1 + 深度 L1 损失），输出亚厘米级位姿（ATE RMSE 最低 0.36cm）|
| **探索策略** | 主动 “前沿优先” 策略：通过检测 “已探索 - 未探索边界”，选择最近可达前沿点，驱动智能体移动探索 | 被动 “随相机移动建图”：无主动探索逻辑，需外部策略（如 GaussianNav 的前沿探索）驱动相机移动，仅负责实时更新地图与位姿 |
| **地图构建** | 基于 “探索地图 + 障碍地图” 构建，精度依赖地图构建质量 | 实时输出 “高保真 3D 高斯地图”，精度高，但存在冗余信息 |
| **数据处理逻辑** | 仅 “采集数据”，不实时优化 3D 高斯参数（高斯构建是探索后的独立阶段）| “边采集边优化”：每帧数据均用于更新相机位姿与高斯参数（如颜色、不透明度），地图实时迭代收敛 |
| **与3D高斯交互** | 不直接操作高斯，仅为后续 “语义高斯构建” 提供原始 RGB-D 与位姿输入 | 直接操作高斯：通过致密化新增高斯、通过梯度优化更新高斯参数，是 3D 高斯地图的 “实时构建者” |

<br>

## 三、 有无可以改进的空间

根据文章提到的局限性与可改进的地方，并结合我个人的理解，我认为可以从以下几个方面进行尝试：

1. 由于SplaTAM属于上游任务，核心能力正是 “实时输出精准相机位姿 + 稠密 3D 高斯地图”，正好与GaussianNav 的前沿探索阶段的核心目标相吻合，所以我认为可以将GaussianNav的探索阶段与SplaTAM的跟踪阶段进行合并，形成一个新的SLAM任务，以生成高精度实时相机位姿
<br>

2. GaussianNav中提取关键点使用了DISK和lightglue，可以尝试更换为鲁棒性更强，效果更强的OmniGlue网络，实现复杂变换角度的精准匹配。
<br>

3. 为实现更精细的地图建模，可以考虑使用PGSR代替3DGS，增加了多种不同约束loss计算，使得地图更加精细。
<br>

4. GaussianNav或者SplaTAM在使用RGB-D获取当前帧深度数据时，可以尝试使用MoGe2单目深度估计网络，减少设备成本但同时又能保留深度获取功能。

